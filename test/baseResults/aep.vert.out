
Top IR:
; ModuleID = 'Glslang'

%ubName = type { <2 x float> }
%outName = type { <4 x float> }

@inf = global <2 x float> zeroinitializer
@ing = global <2 x float> zeroinitializer
@inch = global <2 x float> zeroinitializer
@iArray = external addrspace(1) constant [5 x i32]
@index = external addrspace(2) constant i32
@sArray = external addrspace(1) constant [4 x i32]
@ubInst = external addrspace(2) constant [4 x %ubName]
@color = internal constant [4 x <2 x i32>] [<2 x i32> <i32 1, i32 1>, <2 x i32> <i32 2, i32 2>, <2 x i32> <i32 3, i32 3>, <2 x i32> <i32 4, i32 4>]
@outInst = global %outName zeroinitializer
@bufSamp1 = external addrspace(1) constant i32
@bufSamp2 = external addrspace(1) constant i32
@bufSamp3 = external addrspace(1) constant i32
@bufSamp4 = external addrspace(1) constant i32
@bufSamp5 = external addrspace(1) constant i32
@bufSamp6 = external addrspace(1) constant i32
@CA4 = external addrspace(1) constant i32
@CA5 = external addrspace(1) constant i32
@CA6 = external addrspace(1) constant i32
@CA7 = external addrspace(1) constant i32
@CA1 = external addrspace(1) constant i32
@CA2 = external addrspace(1) constant i32
@CA3 = external addrspace(1) constant i32
@samp2DMSA = external addrspace(1) constant i32
@samp2DMSAi = external addrspace(1) constant i32
@samp2DMSAu = external addrspace(1) constant i32
@im2Di = external addrspace(1) constant i32
@P = external addrspace(2) constant <2 x i32>
@im2Du = external addrspace(1) constant i32
@im2Df = external addrspace(1) constant i32
@gl_VertexID = global i32 0
@gl_InstanceID = global i32 0

define fastcc void @main() {
entry:
  %constOffsets = alloca [4 x <2 x i32>]
  %color = alloca <4 x float>
  %p = alloca <2 x float>
  br label %mainBody

mainBody:                                         ; preds = %entry
  %0 = load <2 x float>* @inf
  %1 = load <2 x float>* @ing
  %2 = load <2 x float>* @inch
  %p2 = call <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float> %0, <2 x float> %1, <2 x float> %2), !gla.precision !85
  store <2 x float> %p2, <2 x float>* %p
  %3 = load i32 addrspace(2)* @index, !gla.uniform !14
  store <4 x float> zeroinitializer, <4 x float>* %color
  %4 = load i32 addrspace(2)* @index, !gla.uniform !14
  %5 = getelementptr [4 x i32] addrspace(1)* @sArray, i32 0, i32 %4
  %6 = load i32 addrspace(1)* %5, !gla.uniform !16
  %7 = load i32 addrspace(2)* @index, !gla.uniform !14
  %8 = getelementptr [4 x %ubName] addrspace(2)* @ubInst, i32 0, i32 %7, i32 0
  %9 = load <2 x float> addrspace(2)* %8, !gla.uniform !19
  %10 = load <2 x float>* @inf
  %11 = fptosi <2 x float> %10 to <2 x i32>, !gla.precision !85
  %color3 = call <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32 2, i32 %6, i32 320, <2 x float> %9, i32 undef, float undef, <2 x i32> %11), !gla.precision !85
  %12 = load <4 x float>* %color
  %color4 = fadd <4 x float> %12, %color3, !gla.precision !85
  store <4 x float> %color4, <4 x float>* %color
  %13 = load i32 addrspace(2)* @index, !gla.uniform !14
  %14 = getelementptr [4 x i32] addrspace(1)* @sArray, i32 0, i32 %13
  %15 = load i32 addrspace(1)* %14, !gla.uniform !16
  %16 = load <2 x float>* %p
  %17 = load [4 x <2 x i32>]* @color
  %18 = extractvalue [4 x <2 x i32>] %17, 0
  %19 = extractvalue [4 x <2 x i32>] %17, 1
  %20 = extractvalue [4 x <2 x i32>] %17, 2
  %21 = extractvalue [4 x <2 x i32>] %17, 3
  %color5 = call <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32 2, i32 %15, i32 8512, <2 x float> %16, i32 undef, float undef, <2 x i32> %18, <2 x i32> %19, <2 x i32> %20, <2 x i32> %21), !gla.precision !85
  %22 = load <4 x float>* %color
  %color6 = fadd <4 x float> %22, %color5, !gla.precision !85
  store <4 x float> %color6, <4 x float>* %color
  %23 = load <4 x float>* %color
  store <4 x float> %23, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %24 = call <4 x float> @"bufferT("()
  %25 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %26 = fadd <4 x float> %25, %24, !gla.precision !85
  store <4 x float> %26, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %27 = call <4 x float> @"CAT("()
  %28 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %29 = fadd <4 x float> %28, %27, !gla.precision !85
  store <4 x float> %29, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %30 = call <4 x float> @"MSA("()
  %31 = load <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  %32 = fadd <4 x float> %31, %30, !gla.precision !85
  store <4 x float> %32, <4 x float>* getelementptr inbounds (%outName* @outInst, i32 0, i32 0)
  call void @"goodImageAtom("()
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %mainBody
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"bufferT("() #0 {
entry:
  %v23 = alloca <4 x float>
  %v19 = alloca <4 x float>
  %v15 = alloca <4 x float>
  %v11 = alloca <4 x float>
  %v7 = alloca <4 x float>
  %v3 = alloca <4 x float>
  %s1 = alloca i32
  %v = alloca <4 x float>
  store <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float>* %v
  %0 = load i32 addrspace(1)* @bufSamp1, !gla.uniform !23
  %s12 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %0), !gla.precision !85
  store i32 %s12, i32* %s1
  %1 = load i32* %s1
  %2 = sitofp i32 %1 to float, !gla.precision !85
  %3 = load <4 x float>* %v3
  %4 = insertelement <4 x float> undef, float %2, i32 0, !gla.precision !85
  %5 = insertelement <4 x float> %4, float %2, i32 1, !gla.precision !85
  %6 = insertelement <4 x float> %5, float %2, i32 2, !gla.precision !85
  %7 = insertelement <4 x float> %6, float %2, i32 3, !gla.precision !85
  %8 = load <4 x float>* %v
  %v4 = fmul <4 x float> %8, %7, !gla.precision !85
  store <4 x float> %v4, <4 x float>* %v
  %9 = load i32 addrspace(1)* @bufSamp2, !gla.uniform !26
  %s16 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %9), !gla.precision !85
  store i32 %s16, i32* %s1
  %10 = load i32* %s1
  %11 = sitofp i32 %10 to float, !gla.precision !85
  %12 = load <4 x float>* %v7
  %13 = insertelement <4 x float> undef, float %11, i32 0, !gla.precision !85
  %14 = insertelement <4 x float> %13, float %11, i32 1, !gla.precision !85
  %15 = insertelement <4 x float> %14, float %11, i32 2, !gla.precision !85
  %16 = insertelement <4 x float> %15, float %11, i32 3, !gla.precision !85
  %17 = load <4 x float>* %v
  %v8 = fmul <4 x float> %17, %16, !gla.precision !85
  store <4 x float> %v8, <4 x float>* %v
  %18 = load i32 addrspace(1)* @bufSamp3, !gla.uniform !29
  %s110 = call i32 @llvm.gla.queryTextureSizeNoLod.i32(i32 0, i32 %18), !gla.precision !85
  store i32 %s110, i32* %s1
  %19 = load i32* %s1
  %20 = sitofp i32 %19 to float, !gla.precision !85
  %21 = load <4 x float>* %v11
  %22 = insertelement <4 x float> undef, float %20, i32 0, !gla.precision !85
  %23 = insertelement <4 x float> %22, float %20, i32 1, !gla.precision !85
  %24 = insertelement <4 x float> %23, float %20, i32 2, !gla.precision !85
  %25 = insertelement <4 x float> %24, float %20, i32 3, !gla.precision !85
  %26 = load <4 x float>* %v
  %v12 = fmul <4 x float> %26, %25, !gla.precision !85
  store <4 x float> %v12, <4 x float>* %v
  %27 = load i32 addrspace(1)* @bufSamp4, !gla.uniform !32
  %s114 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %27), !gla.precision !85
  store i32 %s114, i32* %s1
  %28 = load i32* %s1
  %29 = sitofp i32 %28 to float, !gla.precision !85
  %30 = load <4 x float>* %v15
  %31 = insertelement <4 x float> undef, float %29, i32 0, !gla.precision !85
  %32 = insertelement <4 x float> %31, float %29, i32 1, !gla.precision !85
  %33 = insertelement <4 x float> %32, float %29, i32 2, !gla.precision !85
  %34 = insertelement <4 x float> %33, float %29, i32 3, !gla.precision !85
  %35 = load <4 x float>* %v
  %v16 = fmul <4 x float> %35, %34, !gla.precision !85
  store <4 x float> %v16, <4 x float>* %v
  %36 = load i32 addrspace(1)* @bufSamp5, !gla.uniform !35
  %s118 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %36), !gla.precision !85
  store i32 %s118, i32* %s1
  %37 = load i32* %s1
  %38 = sitofp i32 %37 to float, !gla.precision !85
  %39 = load <4 x float>* %v19
  %40 = insertelement <4 x float> undef, float %38, i32 0, !gla.precision !85
  %41 = insertelement <4 x float> %40, float %38, i32 1, !gla.precision !85
  %42 = insertelement <4 x float> %41, float %38, i32 2, !gla.precision !85
  %43 = insertelement <4 x float> %42, float %38, i32 3, !gla.precision !85
  %44 = load <4 x float>* %v
  %v20 = fmul <4 x float> %44, %43, !gla.precision !85
  store <4 x float> %v20, <4 x float>* %v
  %45 = load i32 addrspace(1)* @bufSamp6, !gla.uniform !38
  %s122 = call i32 @llvm.gla.queryImageSize.i32(i32 0, i32 %45), !gla.precision !85
  store i32 %s122, i32* %s1
  %46 = load i32* %s1
  %47 = sitofp i32 %46 to float, !gla.precision !85
  %48 = load <4 x float>* %v23
  %49 = insertelement <4 x float> undef, float %47, i32 0, !gla.precision !85
  %50 = insertelement <4 x float> %49, float %47, i32 1, !gla.precision !85
  %51 = insertelement <4 x float> %50, float %47, i32 2, !gla.precision !85
  %52 = insertelement <4 x float> %51, float %47, i32 3, !gla.precision !85
  %53 = load <4 x float>* %v
  %v24 = fmul <4 x float> %53, %52, !gla.precision !85
  store <4 x float> %v24, <4 x float>* %v
  %54 = load i32 addrspace(1)* @bufSamp1, !gla.uniform !23
  %55 = load i32* %s1
  %v25 = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32 0, i32 %54, i32 32, i32 %55, i32 undef, float undef, i32 undef), !gla.precision !85
  %56 = load <4 x float>* %v
  %v26 = fmul <4 x float> %56, %v25, !gla.precision !85
  store <4 x float> %v26, <4 x float>* %v
  %57 = load i32 addrspace(1)* @bufSamp2, !gla.uniform !26
  %58 = load i32* %s1
  %v27 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %57, i32 32, i32 %58, i32 undef, float undef, i32 undef), !gla.precision !85
  %59 = sitofp <4 x i32> %v27 to <4 x float>, !gla.precision !85
  %60 = load <4 x float>* %v
  %v28 = fmul <4 x float> %60, %59, !gla.precision !85
  store <4 x float> %v28, <4 x float>* %v
  %61 = load i32 addrspace(1)* @bufSamp3, !gla.uniform !29
  %62 = load i32* %s1
  %v29 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32 0, i32 %61, i32 32, i32 %62, i32 undef, float undef, i32 undef), !gla.precision !85
  %63 = uitofp <4 x i32> %v29 to <4 x float>, !gla.precision !85
  %64 = load <4 x float>* %v
  %v30 = fmul <4 x float> %64, %63, !gla.precision !85
  store <4 x float> %v30, <4 x float>* %v
  %65 = load <4 x float>* %v
  ret <4 x float> %65

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"CAT("() #0 {
entry:
  %v15 = alloca <4 x float>
  %v = alloca <4 x float>
  %iv = alloca <3 x i32>
  store <3 x i32> zeroinitializer, <3 x i32>* %iv
  %0 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %iv1 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %0, i32 1), !gla.precision !85
  %1 = load <3 x i32>* %iv
  %iv2 = add <3 x i32> %1, %iv1, !gla.precision !85
  store <3 x i32> %iv2, <3 x i32>* %iv
  %2 = load i32 addrspace(1)* @CA5, !gla.uniform !44
  %iv3 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %2, i32 1), !gla.precision !85
  %3 = load <3 x i32>* %iv
  %iv4 = add <3 x i32> %3, %iv3, !gla.precision !85
  store <3 x i32> %iv4, <3 x i32>* %iv
  %4 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %iv5 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %4, i32 1), !gla.precision !85
  %5 = load <3 x i32>* %iv
  %iv6 = add <3 x i32> %5, %iv5, !gla.precision !85
  store <3 x i32> %iv6, <3 x i32>* %iv
  %6 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %iv7 = call <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32 4, i32 %6, i32 1), !gla.precision !85
  %7 = load <3 x i32>* %iv
  %iv8 = add <3 x i32> %7, %iv7, !gla.precision !85
  store <3 x i32> %iv8, <3 x i32>* %iv
  %8 = load i32 addrspace(1)* @CA1, !gla.uniform !53
  %iv9 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %8), !gla.precision !85
  %9 = load <3 x i32>* %iv
  %iv10 = add <3 x i32> %9, %iv9, !gla.precision !85
  store <3 x i32> %iv10, <3 x i32>* %iv
  %10 = load i32 addrspace(1)* @CA2, !gla.uniform !56
  %iv11 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %10), !gla.precision !85
  %11 = load <3 x i32>* %iv
  %iv12 = add <3 x i32> %11, %iv11, !gla.precision !85
  store <3 x i32> %iv12, <3 x i32>* %iv
  %12 = load i32 addrspace(1)* @CA3, !gla.uniform !59
  %iv13 = call <3 x i32> @llvm.gla.queryImageSize.v3i32(i32 4, i32 %12), !gla.precision !85
  %13 = load <3 x i32>* %iv
  %iv14 = add <3 x i32> %13, %iv13, !gla.precision !85
  store <3 x i32> %iv14, <3 x i32>* %iv
  %14 = load <3 x i32>* %iv
  %15 = sitofp <3 x i32> %14 to <3 x float>, !gla.precision !85
  %16 = load <4 x float>* %v15
  %17 = extractelement <3 x float> %15, i32 0, !gla.precision !85
  %18 = insertelement <4 x float> %16, float %17, i32 0, !gla.precision !85
  %19 = extractelement <3 x float> %15, i32 1, !gla.precision !85
  %20 = insertelement <4 x float> %18, float %19, i32 1, !gla.precision !85
  %21 = extractelement <3 x float> %15, i32 2, !gla.precision !85
  %22 = insertelement <4 x float> %20, float %21, i32 2, !gla.precision !85
  %v16 = insertelement <4 x float> %22, float 1.000000e+00, i32 3, !gla.precision !85
  store <4 x float> %v16, <4 x float>* %v
  %23 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %v17 = call <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32 4, i32 %23, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !85
  %24 = load <4 x float>* %v
  %v18 = fmul <4 x float> %24, %v17, !gla.precision !85
  store <4 x float> %v18, <4 x float>* %v
  %25 = load i32 addrspace(1)* @CA5, !gla.uniform !44
  %v19 = call float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32 4, i32 %25, i32 154, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 3.000000e+00, float undef), !gla.precision !85
  %26 = load <4 x float>* %v
  %27 = insertelement <4 x float> undef, float %v19, i32 0, !gla.precision !85
  %28 = insertelement <4 x float> %27, float %v19, i32 1, !gla.precision !85
  %29 = insertelement <4 x float> %28, float %v19, i32 2, !gla.precision !85
  %30 = insertelement <4 x float> %29, float %v19, i32 3, !gla.precision !85
  %v20 = fmul <4 x float> %26, %30, !gla.precision !85
  store <4 x float> %v20, <4 x float>* %v
  %31 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %v21 = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %31, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !85
  %32 = sitofp <4 x i32> %v21 to <4 x float>, !gla.precision !85
  %33 = load <4 x float>* %v
  %v22 = fmul <4 x float> %33, %32, !gla.precision !85
  store <4 x float> %v22, <4 x float>* %v
  %34 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %v23 = call <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32 4, i32 %34, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>), !gla.precision !85
  %35 = uitofp <4 x i32> %v23 to <4 x float>, !gla.precision !85
  %36 = load <4 x float>* %v
  %v24 = fmul <4 x float> %36, %35, !gla.precision !85
  store <4 x float> %v24, <4 x float>* %v
  %37 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %v25 = call <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32 4, i32 %37, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FCEB851E0000000, float undef), !gla.precision !85
  %38 = load <4 x float>* %v
  %v26 = fmul <4 x float> %38, %v25, !gla.precision !85
  store <4 x float> %v26, <4 x float>* %v
  %39 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %v27 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %39, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD0A3D700000000, float undef), !gla.precision !85
  %40 = sitofp <4 x i32> %v27 to <4 x float>, !gla.precision !85
  %41 = load <4 x float>* %v
  %v28 = fmul <4 x float> %41, %40, !gla.precision !85
  store <4 x float> %v28, <4 x float>* %v
  %42 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %v29 = call <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32 4, i32 %42, i32 148, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float 0x3FD147AE20000000, float undef), !gla.precision !85
  %43 = uitofp <4 x i32> %v29 to <4 x float>, !gla.precision !85
  %44 = load <4 x float>* %v
  %v30 = fmul <4 x float> %44, %43, !gla.precision !85
  store <4 x float> %v30, <4 x float>* %v
  %45 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %v31 = call <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32 4, i32 %45, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !85
  %46 = load <4 x float>* %v
  %v32 = fmul <4 x float> %46, %v31, !gla.precision !85
  store <4 x float> %v32, <4 x float>* %v
  %47 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %v33 = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %47, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !85
  %48 = sitofp <4 x i32> %v33 to <4 x float>, !gla.precision !85
  %49 = load <4 x float>* %v
  %v34 = fmul <4 x float> %49, %48, !gla.precision !85
  store <4 x float> %v34, <4 x float>* %v
  %50 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %v35 = call <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32 4, i32 %50, i32 16, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, float undef, float undef, i32 undef, <3 x float> <float 0x3FB99999A0000000, float 0x3FB99999A0000000, float 0x3FB99999A0000000>, <3 x float> <float 0x3FC99999A0000000, float 0x3FC99999A0000000, float 0x3FC99999A0000000>), !gla.precision !85
  %51 = uitofp <4 x i32> %v35 to <4 x float>, !gla.precision !85
  %52 = load <4 x float>* %v
  %v36 = fmul <4 x float> %52, %51, !gla.precision !85
  store <4 x float> %v36, <4 x float>* %v
  %53 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %v37 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %53, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !85
  %54 = load <4 x float>* %v
  %v38 = fmul <4 x float> %54, %v37, !gla.precision !85
  store <4 x float> %v38, <4 x float>* %v
  %55 = load i32 addrspace(1)* @CA4, !gla.uniform !41
  %v39 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %55, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 2, float undef), !gla.precision !85
  %56 = load <4 x float>* %v
  %v40 = fmul <4 x float> %56, %v39, !gla.precision !85
  store <4 x float> %v40, <4 x float>* %v
  %57 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %v41 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %57, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !85
  %58 = sitofp <4 x i32> %v41 to <4 x float>, !gla.precision !85
  %59 = load <4 x float>* %v
  %v42 = fmul <4 x float> %59, %58, !gla.precision !85
  store <4 x float> %v42, <4 x float>* %v
  %60 = load i32 addrspace(1)* @CA6, !gla.uniform !47
  %v43 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %60, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 1, float undef), !gla.precision !85
  %61 = sitofp <4 x i32> %v43 to <4 x float>, !gla.precision !85
  %62 = load <4 x float>* %v
  %v44 = fmul <4 x float> %62, %61, !gla.precision !85
  store <4 x float> %v44, <4 x float>* %v
  %63 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %v45 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %63, i32 80, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float undef), !gla.precision !85
  %64 = uitofp <4 x i32> %v45 to <4 x float>, !gla.precision !85
  %65 = load <4 x float>* %v
  %v46 = fmul <4 x float> %65, %64, !gla.precision !85
  store <4 x float> %v46, <4 x float>* %v
  %66 = load i32 addrspace(1)* @CA7, !gla.uniform !50
  %v47 = call <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32 4, i32 %66, i32 1104, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 0, float undef), !gla.precision !85
  %67 = uitofp <4 x i32> %v47 to <4 x float>, !gla.precision !85
  %68 = load <4 x float>* %v
  %v48 = fmul <4 x float> %68, %67, !gla.precision !85
  store <4 x float> %v48, <4 x float>* %v
  %69 = load i32 addrspace(1)* @CA5, !gla.uniform !44
  %v49 = call <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32 4, i32 %69, i32 2136, <4 x float> <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>, i32 undef, float 2.500000e+00), !gla.precision !85
  %70 = load <4 x float>* %v
  %v50 = fmul <4 x float> %70, %v49, !gla.precision !85
  store <4 x float> %v50, <4 x float>* %v
  %71 = load <4 x float>* %v
  ret <4 x float> %71

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc <4 x float> @"MSA("() #0 {
entry:
  %v7 = alloca <4 x float>
  %v = alloca <4 x float>
  %iv = alloca <3 x i32>
  store <3 x i32> zeroinitializer, <3 x i32>* %iv
  %0 = load i32 addrspace(1)* @samp2DMSA, !gla.uniform !62
  %iv1 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %0), !gla.precision !85
  %1 = load <3 x i32>* %iv
  %iv2 = add <3 x i32> %1, %iv1, !gla.precision !85
  store <3 x i32> %iv2, <3 x i32>* %iv
  %2 = load i32 addrspace(1)* @samp2DMSAi, !gla.uniform !65
  %iv3 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %2), !gla.precision !85
  %3 = load <3 x i32>* %iv
  %iv4 = add <3 x i32> %3, %iv3, !gla.precision !85
  store <3 x i32> %iv4, <3 x i32>* %iv
  %4 = load i32 addrspace(1)* @samp2DMSAu, !gla.uniform !68
  %iv5 = call <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32 6, i32 %4), !gla.precision !85
  %5 = load <3 x i32>* %iv
  %iv6 = add <3 x i32> %5, %iv5, !gla.precision !85
  store <3 x i32> %iv6, <3 x i32>* %iv
  %6 = load <3 x i32>* %iv
  %7 = sitofp <3 x i32> %6 to <3 x float>, !gla.precision !85
  %8 = load <4 x float>* %v7
  %9 = extractelement <3 x float> %7, i32 0, !gla.precision !85
  %10 = insertelement <4 x float> %8, float %9, i32 0, !gla.precision !85
  %11 = extractelement <3 x float> %7, i32 1, !gla.precision !85
  %12 = insertelement <4 x float> %10, float %11, i32 1, !gla.precision !85
  %13 = extractelement <3 x float> %7, i32 2, !gla.precision !85
  %14 = insertelement <4 x float> %12, float %13, i32 2, !gla.precision !85
  %v8 = insertelement <4 x float> %14, float 1.000000e+00, i32 3, !gla.precision !85
  store <4 x float> %v8, <4 x float>* %v
  %15 = load i32 addrspace(1)* @samp2DMSA, !gla.uniform !62
  %v9 = call <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32 6, i32 %15, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !85
  %16 = load <4 x float>* %v
  %v10 = fmul <4 x float> %16, %v9, !gla.precision !85
  store <4 x float> %v10, <4 x float>* %v
  %17 = load i32 addrspace(1)* @samp2DMSAi, !gla.uniform !65
  %v11 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %17, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !85
  %18 = sitofp <4 x i32> %v11 to <4 x float>, !gla.precision !85
  %19 = load <4 x float>* %v
  %v12 = fmul <4 x float> %19, %18, !gla.precision !85
  store <4 x float> %v12, <4 x float>* %v
  %20 = load i32 addrspace(1)* @samp2DMSAu, !gla.uniform !68
  %v13 = call <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32 6, i32 %20, i32 688, <3 x i32> <i32 5, i32 5, i32 5>, i32 2, float undef, i32 undef), !gla.precision !85
  %21 = uitofp <4 x i32> %v13 to <4 x float>, !gla.precision !85
  %22 = load <4 x float>* %v
  %v14 = fmul <4 x float> %22, %21, !gla.precision !85
  store <4 x float> %v14, <4 x float>* %v
  %23 = load <4 x float>* %v
  ret <4 x float> %23

post-return:                                      ; No predecessors!
  unreachable
}

; Function Attrs: alwaysinline
define internal fastcc void @"goodImageAtom("() #0 {
entry:
  %datu = alloca i32
  %dati = alloca i32
  %datf = alloca float
  store float 0x3FFCCCCCC0000000, float* %datf
  store i32 4, i32* %dati
  store i32 7, i32* %datu
  %0 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %1 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %2 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %3 = extractelement <2 x i32> %2, i32 0, !gla.precision !85
  %4 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %0, <2 x i32> %1, i32 %3), !gla.precision !85
  %5 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %6 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %7 = load i32* %datu
  %8 = call i32 @llvm.gla.imageAtomicAdd.v2i32(i32 2, i32 %5, <2 x i32> %6, i32 %7), !gla.precision !85
  %9 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %10 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %11 = load i32* %dati
  %12 = call i32 @llvm.gla.sImageAtomicMin.v2i32(i32 2, i32 %9, <2 x i32> %10, i32 %11), !gla.precision !85
  %13 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %14 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %15 = load i32* %datu
  %16 = call i32 @llvm.gla.uImageAtomicMin.v2i32(i32 2, i32 %13, <2 x i32> %14, i32 %15), !gla.precision !85
  %17 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %18 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %19 = load i32* %dati
  %20 = call i32 @llvm.gla.sImageAtomicMax.v2i32(i32 2, i32 %17, <2 x i32> %18, i32 %19), !gla.precision !85
  %21 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %22 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %23 = load i32* %datu
  %24 = call i32 @llvm.gla.uImageAtomicMax.v2i32(i32 2, i32 %21, <2 x i32> %22, i32 %23), !gla.precision !85
  %25 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %26 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %27 = load i32* %dati
  %28 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %25, <2 x i32> %26, i32 %27), !gla.precision !85
  %29 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %30 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %31 = load i32* %datu
  %32 = call i32 @llvm.gla.imageAtomicAnd.v2i32(i32 2, i32 %29, <2 x i32> %30, i32 %31), !gla.precision !85
  %33 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %34 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %35 = load i32* %dati
  %36 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %33, <2 x i32> %34, i32 %35), !gla.precision !85
  %37 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %38 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %39 = load i32* %datu
  %40 = call i32 @llvm.gla.imageAtomicOr.v2i32(i32 2, i32 %37, <2 x i32> %38, i32 %39), !gla.precision !85
  %41 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %42 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %43 = load i32* %dati
  %44 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %41, <2 x i32> %42, i32 %43), !gla.precision !85
  %45 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %46 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %47 = load i32* %datu
  %48 = call i32 @llvm.gla.imageAtomicXor.v2i32(i32 2, i32 %45, <2 x i32> %46, i32 %47), !gla.precision !85
  %49 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %50 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %51 = load i32* %dati
  %52 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %49, <2 x i32> %50, i32 %51), !gla.precision !85
  %53 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %54 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %55 = load i32* %datu
  %56 = call i32 @llvm.gla.iImageAtomicExchange.v2i32(i32 2, i32 %53, <2 x i32> %54, i32 %55), !gla.precision !85
  %57 = load i32 addrspace(1)* @im2Df, !gla.uniform !78
  %58 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %59 = load float* %datf
  %60 = call float @llvm.gla.fImageAtomicExchange.v2i32(i32 2, i32 %57, <2 x i32> %58, float %59), !gla.precision !85
  %61 = load i32 addrspace(1)* @im2Di, !gla.uniform !71
  %62 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %63 = load i32* %dati
  %64 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %61, <2 x i32> %62, i32 3, i32 %63), !gla.precision !85
  %65 = load i32 addrspace(1)* @im2Du, !gla.uniform !75
  %66 = load <2 x i32> addrspace(2)* @P, !gla.uniform !74
  %67 = load i32* %datu
  %68 = call i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32 2, i32 %65, <2 x i32> %66, i32 5, i32 %67), !gla.precision !85
  ret void
}

; Function Attrs: nounwind readnone
declare <2 x float> @llvm.gla.fFma.v2f32.v2f32.v2f32.v2f32(<2 x float>, <2 x float>, <2 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffset.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGatherOffsets.v4f32.v2f32(i32, i32, i32, <2 x float>, i32, float, <2 x i32>, <2 x i32>, <2 x i32>, <2 x i32>) #1

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryTextureSizeNoLod.i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare i32 @llvm.gla.queryImageSize.i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.i32.i32.i32(i32, i32, i32, i32, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSize.v3i32(i32, i32, i32) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryImageSize.v3i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSample.v4f32.v4f32(i32, i32, i32, <4 x float>) #1

; Function Attrs: nounwind readnone
declare float @llvm.gla.fTextureSampleLodRefZ.f32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSample.v4i32.v4f32(i32, i32, i32, <4 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZ.v4f32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZ.v4i32.v4f32(i32, i32, i32, <4 x float>, float, float) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTextureSampleLodRefZOffsetGrad.v4f32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.textureSampleLodRefZOffsetGrad.v4i32.v4f32.i32.v3f32.v3f32(i32, i32, i32, <4 x float>, float, float, i32, <3 x float>, <3 x float>) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelGather.v4f32.v4f32(i32, i32, i32, <4 x float>, i32, float) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelGather.v4i32.v4f32(i32, i32, i32, <4 x float>, i32, float) #1

; Function Attrs: nounwind readnone
declare <3 x i32> @llvm.gla.queryTextureSizeNoLod.v3i32(i32, i32) #1

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTexelFetchOffset.v4f32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #1

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.gla.texelFetchOffset.v4i32.v3i32.i32.i32(i32, i32, i32, <3 x i32>, i32, float, i32) #1

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAdd.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMin.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.sImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.uImageAtomicMax.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicAnd.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicOr.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicXor.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.iImageAtomicExchange.v2i32(i32, i32, <2 x i32>, i32) #2

; Function Attrs: nounwind
declare float @llvm.gla.fImageAtomicExchange.v2i32(i32, i32, <2 x i32>, float) #2

; Function Attrs: nounwind
declare i32 @llvm.gla.imageAtomicCompExchange.v2i32(i32, i32, <2 x i32>, i32, i32) #2

attributes #0 = { alwaysinline }
attributes #1 = { nounwind readnone }
attributes #2 = { nounwind }

!gla.entrypoint = !{!0}
!gla.inputs = !{!1, !3, !5, !7, !9}
!gla.uniforms = !{!11, !14, !16, !19, !23, !26, !29, !32, !35, !38, !41, !44, !47, !50, !53, !56, !59, !62, !65, !68, !71, !74, !75, !78}
!gla.outputs = !{!81}
!gla.noStaticUse = !{!7, !9}

!0 = !{!"main", i32 15}
!1 = !{!"inf", i32 1, <2 x float>* @inf_typeProxy, !2}
!2 = !{i32 0, i32 3, i32 1024, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!3 = !{!"ing", i32 1, <2 x float>* @ing_typeProxy, !4}
!4 = !{i32 0, i32 3, i32 1025, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!5 = !{!"inch", i32 1, <2 x float>* @inch_typeProxy, !6}
!6 = !{i32 0, i32 3, i32 1026, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!7 = !{!"gl_VertexID", i32 2, i32* @gl_VertexID_typeProxy, !8}
!8 = !{i32 0, i32 3, i32 1028, null, i32 0, i32 7, i32 -1, i32 0, i32 -1}
!9 = !{!"gl_InstanceID", i32 3, i32* @gl_InstanceID_typeProxy, !10}
!10 = !{i32 0, i32 3, i32 1029, null, i32 0, i32 8, i32 -1, i32 0, i32 -1}
!11 = !{!"iArray", i32 12, [5 x i32]* @iArray_typeProxy, !12}
!12 = !{i32 5, i32 1, i32 1024, !13, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!13 = !{i32 1, [5 x i32]* @iArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!14 = !{!"index", i32 12, i32* @index_typeProxy, !15}
!15 = !{i32 0, i32 3, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!16 = !{!"sArray", i32 12, [4 x i32]* @sArray_typeProxy, !17}
!17 = !{i32 5, i32 1, i32 1024, !18, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!18 = !{i32 0, [4 x i32]* @sArray_typeProxy, i32 1, i1 false, i1 false, i32 0}
!19 = !{!"ubInst", i32 13, [4 x %ubName]* @ubInst_typeProxy, !20, !21}
!20 = !{i32 6, i32 0, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!21 = !{!"ubName", !20, !"p", !22}
!22 = !{!"", !15}
!23 = !{!"bufSamp1", i32 12, i32* @bufSamp1_typeProxy, !24}
!24 = !{i32 5, i32 3, i32 1024, !25, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!25 = !{i32 0, i32* @bufSamp1_typeProxy, i32 5, i1 false, i1 false, i32 0}
!26 = !{!"bufSamp2", i32 12, i32* @bufSamp2_typeProxy, !27}
!27 = !{i32 5, i32 3, i32 1024, !28, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!28 = !{i32 0, i32* @bufSamp2_typeProxy, i32 5, i1 false, i1 false, i32 1}
!29 = !{!"bufSamp3", i32 12, i32* @bufSamp3_typeProxy, !30}
!30 = !{i32 5, i32 3, i32 1024, !31, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!31 = !{i32 0, i32* @bufSamp3_typeProxy, i32 5, i1 false, i1 false, i32 2}
!32 = !{!"bufSamp4", i32 12, i32* @bufSamp4_typeProxy, !33}
!33 = !{i32 5, i32 3, i32 1024, !34, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!34 = !{i32 1, i32* @bufSamp4_typeProxy, i32 5, i1 false, i1 false, i32 0}
!35 = !{!"bufSamp5", i32 12, i32* @bufSamp5_typeProxy, !36}
!36 = !{i32 5, i32 3, i32 1024, !37, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!37 = !{i32 1, i32* @bufSamp5_typeProxy, i32 5, i1 false, i1 false, i32 1}
!38 = !{!"bufSamp6", i32 12, i32* @bufSamp6_typeProxy, !39}
!39 = !{i32 5, i32 3, i32 1024, !40, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!40 = !{i32 1, i32* @bufSamp6_typeProxy, i32 5, i1 false, i1 false, i32 2}
!41 = !{!"CA4", i32 12, i32* @CA4_typeProxy, !42}
!42 = !{i32 5, i32 3, i32 1024, !43, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!43 = !{i32 0, i32* @CA4_typeProxy, i32 3, i1 true, i1 false, i32 0}
!44 = !{!"CA5", i32 12, i32* @CA5_typeProxy, !45}
!45 = !{i32 5, i32 3, i32 1024, !46, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!46 = !{i32 0, i32* @CA5_typeProxy, i32 3, i1 true, i1 true, i32 0}
!47 = !{!"CA6", i32 12, i32* @CA6_typeProxy, !48}
!48 = !{i32 5, i32 3, i32 1024, !49, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!49 = !{i32 0, i32* @CA6_typeProxy, i32 3, i1 true, i1 false, i32 1}
!50 = !{!"CA7", i32 12, i32* @CA7_typeProxy, !51}
!51 = !{i32 5, i32 3, i32 1024, !52, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!52 = !{i32 0, i32* @CA7_typeProxy, i32 3, i1 true, i1 false, i32 2}
!53 = !{!"CA1", i32 12, i32* @CA1_typeProxy, !54}
!54 = !{i32 5, i32 3, i32 1024, !55, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!55 = !{i32 1, i32* @CA1_typeProxy, i32 3, i1 true, i1 false, i32 0}
!56 = !{!"CA2", i32 12, i32* @CA2_typeProxy, !57}
!57 = !{i32 5, i32 3, i32 1024, !58, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!58 = !{i32 1, i32* @CA2_typeProxy, i32 3, i1 true, i1 false, i32 1}
!59 = !{!"CA3", i32 12, i32* @CA3_typeProxy, !60}
!60 = !{i32 5, i32 3, i32 1024, !61, i32 -1, i32 0, i32 -1, i32 1, i32 -1}
!61 = !{i32 1, i32* @CA3_typeProxy, i32 3, i1 true, i1 false, i32 2}
!62 = !{!"samp2DMSA", i32 12, i32* @samp2DMSA_typeProxy, !63}
!63 = !{i32 5, i32 3, i32 1024, !64, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!64 = !{i32 0, i32* @samp2DMSA_typeProxy, i32 6, i1 true, i1 false, i32 0}
!65 = !{!"samp2DMSAi", i32 12, i32* @samp2DMSAi_typeProxy, !66}
!66 = !{i32 5, i32 3, i32 1024, !67, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!67 = !{i32 0, i32* @samp2DMSAi_typeProxy, i32 6, i1 true, i1 false, i32 1}
!68 = !{!"samp2DMSAu", i32 12, i32* @samp2DMSAu_typeProxy, !69}
!69 = !{i32 5, i32 3, i32 1024, !70, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!70 = !{i32 0, i32* @samp2DMSAu_typeProxy, i32 6, i1 true, i1 false, i32 2}
!71 = !{!"im2Di", i32 12, i32* @im2Di_typeProxy, !72}
!72 = !{i32 5, i32 3, i32 1024, !73, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!73 = !{i32 25, i32* @im2Di_typeProxy, i32 1, i1 false, i1 false, i32 1}
!74 = !{!"P", i32 12, <2 x i32>* @P_typeProxy, !15}
!75 = !{!"im2Du", i32 12, i32* @im2Du_typeProxy, !76}
!76 = !{i32 5, i32 3, i32 1024, !77, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!77 = !{i32 34, i32* @im2Du_typeProxy, i32 1, i1 false, i1 false, i32 2}
!78 = !{!"im2Df", i32 12, i32* @im2Df_typeProxy, !79}
!79 = !{i32 5, i32 3, i32 1024, !80, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!80 = !{i32 4, i32* @im2Df_typeProxy, i32 1, i1 false, i1 false, i32 0}
!81 = !{!"outInst", i32 16, %outName* @outInst_typeProxy, !82, !83}
!82 = !{i32 0, i32 0, i32 1027, null, i32 0, i32 0, i32 -1, i32 0, i32 -1}
!83 = !{!"outName", !84, !"color", !22}
!84 = !{i32 0, i32 0, i32 1024, null, i32 -1, i32 0, i32 -1, i32 0, i32 -1}
!85 = !{i32 3}
